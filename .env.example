# LLM Provider
LLM_PROVIDER=groq                          # groq | ollama

# Groq API
GROQ_API_KEY=gsk_your_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
GROQ_REVIEW_MODEL=llama-3.3-70b-versatile  # Optional: larger model for reviews

# Ollama (self-hosted alternative)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# GitHub Integration
GITHUB_TOKEN=ghp_your_personal_access_token
GITHUB_WEBHOOK_SECRET=your_webhook_secret

# Supabase
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# App URL (for edge functions to call back)
APP_URL=https://your-app.vercel.app
NEXT_PUBLIC_APP_URL=https://your-app.vercel.app

# Cron/Worker Auth
CRON_SECRET=your_random_secret_here

# Notifications (optional)
SLACK_WEBHOOK_URL=
DISCORD_WEBHOOK_URL=
